{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idcPdZvg4HFQ"
      },
      "outputs": [],
      "source": [
        "'''extractive QA\n",
        "BERT - squad2.0'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "49wsI-rb4iWv"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60PgZmsqYAyw",
        "outputId": "daf1f34e-e101-479e-f6e4-a1715595b7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rbtdJnJX4iZH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/Projects/BERT QA'):\n",
        "    os.mkdir('/content/drive/MyDrive/Projects/BERT QA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRnTGnH-4iSI",
        "outputId": "0d7cbec1-c3d4-4fe3-e7c7-c681725267c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-13 01:03:43--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.111.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-02-13 01:03:46 (366 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2024-02-13 01:03:46--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.111.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-02-13 01:03:47 (283 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oMTPMnqV4ibi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import requests\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9Ad6G5tS4iP5"
      },
      "outputs": [],
      "source": [
        "with open('train-v2.0.json', 'rb') as f:\n",
        "    squad = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJdEDQhmF55U"
      },
      "outputs": [],
      "source": [
        "#squad['data'][0].keys() -> dict_keys(['title', 'paragraphs']), squad['data'][0], squad['data'][0]['paragraphs'][0]['context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a73N-A_D4iNw"
      },
      "outputs": [],
      "source": [
        "def read_data(path):\n",
        "    \"\"\"\n",
        "    Read SQuAD data from a JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    - path: Path to the JSON file containing SQuAD data\n",
        "\n",
        "    Returns:\n",
        "    - contexts: List of contexts (passages)\n",
        "    - questions: List of questions\n",
        "    - answers: List of answers\n",
        "    \"\"\"\n",
        "    # Open the JSON file and load the data\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        squad = json.load(f)\n",
        "\n",
        "    # Initialize lists to store contexts, questions, and answers\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    # Iterate over groups in the SQuAD data\n",
        "    for group in squad.get('data', []):\n",
        "        # Iterate over paragraphs in the group\n",
        "        for passage in group.get('paragraphs', []):\n",
        "            # Get the context (passage)\n",
        "            context = passage.get('context', '')\n",
        "            # Iterate over questions and answers in the paragraph\n",
        "            for qa in passage.get('qas', []):\n",
        "                # Get the question\n",
        "                question = qa.get('question', '')\n",
        "                # Iterate over answers for the question\n",
        "                for answer in qa.get('answers', []):\n",
        "                    # Append context, question, and answer to their respective lists\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    # Return the lists of contexts, questions, and answers\n",
        "    return contexts, questions, answers\n",
        "\n",
        "# Read training data\n",
        "train_contexts, train_questions, train_answers = read_data('train-v2.0.json')\n",
        "# Read validation data\n",
        "valid_contexts, valid_questions, valid_answers = read_data('dev-v2.0.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QmhZyz9T4iLv"
      },
      "outputs": [],
      "source": [
        "def add_end_index(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # Check if the answer is correctly positioned\n",
        "        for offset in [0, -1, -2]:\n",
        "            if context[start_idx + offset:end_idx + offset] == gold_text:\n",
        "                # Update answer start and end indices\n",
        "                answer['answer_start'] = start_idx + offset\n",
        "                answer['answer_end'] = end_idx + offset\n",
        "                break  # Break loop once correct offset is found\n",
        "\n",
        "add_end_index(train_answers, train_contexts)\n",
        "add_end_index(valid_answers, valid_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "6a1e5d12390a4c50b16a1080ecbd116e",
            "06aafb298e06406ead8ce2d412694b4a",
            "497b79d732b6445e947cb7ee15861953",
            "fc3056d68ce74432ba503305e4dafc46",
            "db8e2eb968724e76a0dde7f8e69c825a",
            "7b3e0ef67aa64e6ebab541017a28f273",
            "00f84bf7038e481d9c0984501690fd75",
            "2dada988d597404bb88b06fa28f9be54",
            "8a02609f0aa54aa9967710cd137bd0d6",
            "c1382ede91cd48aaa6d20c534f82878b",
            "47a16d74ae984ef494be0fa1c948c184",
            "1acce1d7dea14d09b57039baa9c4d524",
            "d25e31523631405aaa5aee90340cbd74",
            "0ca3c72439604224bacbcd32941cf347",
            "d1e5720c1d1341b1a2eea3dd6a2e6f79",
            "3c7f2cfe590449e597ddea87ec27c566",
            "a71adba54b84439cb03c19a5706d806d",
            "cd62b340578a4615975fe06c17dfce2f",
            "c8b09def97ea430f94f515a033bade19",
            "d5338ea914b04a1185a983fec9642b11",
            "a825de9638f7428193afeebd6c262301",
            "3332d175b519437e99cc2f57c754ed5b",
            "363b2a9771e14a53ac146091fd7ce06f",
            "1de52722f83f44f2a2d62b6a75d45436",
            "965414e9b4c34e639a4f9f423852a100",
            "6beeb986f16a491f85bef981ef21eeac",
            "e92cb97cf67f49d9af2038bd957a9537",
            "207e083105734c929fe093b128542fe4",
            "6c3abc9b81614cd39b0ae11f28edb020",
            "b9e6794ab95747da956c28b802995a9c",
            "4c542912183743feb9d966633eead8a2",
            "2e8d2f8be0d9480ebe9a69b7ed19fcac",
            "30f0c693adc44c2a939c5939f28c6864",
            "941f7b33b5134e759ad44b26feaf2c0d",
            "57c8e744b1ff46498d11c89753073e7b",
            "dab4d8388b37478eab5c81e2ad5493b2",
            "dad87cf60ec344ada7caa8d8634c14c6",
            "8a1a906308814fe0a89da55b134649c0",
            "5f709dda46a74ae199ba2aa9be4e5df3",
            "7bc2500103ae447a9ce0c2a7c44e9f72",
            "910f299530a7405bb3da2a311d3d6fa0",
            "dd4940d554d649c9b364c8d88b4a09f0",
            "62fb66562363416fbb543f8553a203ac",
            "e3a8d1cfec4c44e38b5f1dbe0c88fa77"
          ]
        },
        "id": "5CS2kyUV5Frx",
        "outputId": "f6943c18-6604-40f4-873c-0467c916a4c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a1e5d12390a4c50b16a1080ecbd116e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1acce1d7dea14d09b57039baa9c4d524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "363b2a9771e14a53ac146091fd7ce06f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941f7b33b5134e759ad44b26feaf2c0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyGjPbL44iHb"
      },
      "outputs": [],
      "source": [
        "# # Initialize tokenizer\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# # Check if saved encodings exist\n",
        "# if os.path.exists(\"train_encodings.pt\") and os.path.exists(\"valid_encodings.pt\"):\n",
        "#     # Load saved encodings\n",
        "#     train_encodings = torch.load(\"train_encodings.pt\")\n",
        "#     valid_encodings = torch.load(\"valid_encodings.pt\")\n",
        "# else:\n",
        "#     # Generate encodings and save them\n",
        "#     train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "#     valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True)\n",
        "#     torch.save(train_encodings, \"train_encodings.pt\")\n",
        "#     torch.save(valid_encodings, \"valid_encodings.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0nbFrO92vhv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "train_encodings.keys()\n",
        "#dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
        "no_of_encodings = len(train_encodings['input_ids'])\n",
        "print(f'{no_of_encodings} context-question pairs count')\n",
        "tokenizer.decode(train_encodings['input_ids'][0])\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tR3pKb47G6k7"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    \"\"\"\n",
        "    Adds token positions for answers to encodings.\n",
        "\n",
        "    Parameters:\n",
        "    - encodings: Encodings object containing tokenized inputs\n",
        "    - answers: List of dictionaries containing answer positions\n",
        "\n",
        "    Returns:\n",
        "    None (modifies encodings in place)\n",
        "    \"\"\"\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Loop through each answer\n",
        "    for i, answer in enumerate(answers):\n",
        "        # Convert character positions to token positions\n",
        "        start_positions.append(encodings.char_to_token(i, answer['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answer['answer_end'] - 1))\n",
        "\n",
        "        # Handle cases where answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    # Update encodings with start and end positions\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "# Add token positions for training data\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "# Add token positions for validation data\n",
        "add_token_positions(valid_encodings, valid_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZcCcGtA8G6c-"
      },
      "outputs": [],
      "source": [
        "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for SQuAD.\n",
        "\n",
        "    Parameters:\n",
        "    - encodings: Encodings object containing tokenized inputs\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves an item from the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - idx: Index of the item to retrieve\n",
        "\n",
        "        Returns:\n",
        "        Dictionary containing tensors for each key in the encodings\n",
        "        \"\"\"\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "        Integer representing the length of the dataset\n",
        "        \"\"\"\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "# Create training dataset\n",
        "train_dataset = SQuAD_Dataset(train_encodings)\n",
        "# Create validation dataset\n",
        "valid_dataset = SQuAD_Dataset(valid_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GM7jsYEt2R8u"
      },
      "outputs": [],
      "source": [
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a9b5b6a5098642f9879a04f2d112c319",
            "a4f83b6692a54ba69222a8e969e38f62",
            "deb34ba70a58401390a5785f7ea9c902",
            "4e33f3851dc340ea8055735a0d180d7d",
            "d4590c782677412fb6cd7563c413d45a",
            "4b28d8cf21f44e38a2123331cf99eaa4",
            "447b3fc6e01b49429b0e4120bb39c239",
            "185eb78f7f2344fb8bb2d22f4dee993e",
            "c639665ad225412f91d313a0cf5b4bd9",
            "4dfdaf644e92499d9567fb318c228ead",
            "0c1475e26d954587a96e3de6ce7fba09"
          ]
        },
        "id": "bsRlbq9b2R7a",
        "outputId": "23a1caa5-470f-40a8-bf60-fc43875f4175"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9b5b6a5098642f9879a04f2d112c319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE1ngOPOLLF2",
        "outputId": "48d24bf7-a91b-44de-c41b-d026f5fb5e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on cuda\n"
          ]
        }
      ],
      "source": [
        "# Check the available device and use GPU if available, otherwise use CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# Print the device being used\n",
        "print(f'Working on {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq-p7BCKLLE8",
        "outputId": "39b90a62-1768-4390-aa8b-cf71494685fd"
      },
      "outputs": [],
      "source": [
        "# Number of epochs for training: 3-9\n",
        "N_EPOCHS = 3\n",
        "\n",
        "# Optimizer definition\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
        "model.to(device)\n",
        "# Set model in training mode\n",
        "model.train()\n",
        "\n",
        "# Iterate over epochs\n",
        "for epoch in range(N_EPOCHS):\n",
        "    # Create a progress bar for the training data\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    # Iterate over batches in the training data\n",
        "    for batch in loop:\n",
        "        # Zero gradients from previous iteration\n",
        "        optim.zero_grad()\n",
        "        # Move input tensors to the appropriate device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        # Forward pass through the model\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        # Compute the loss\n",
        "        loss = outputs[0]\n",
        "        # Backpropagation: compute gradients\n",
        "        loss.backward()\n",
        "        # Update model parameters\n",
        "        optim.step()\n",
        "\n",
        "        # Update progress bar description with current epoch\n",
        "        loop.set_description(f'Epoch {epoch+1}')\n",
        "        # Update progress bar with current loss\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# Define the path where the model and tokenizer will be saved\n",
        "model_path = '/content/drive/MyDrive/Projects/BERT QA'\n",
        "\n",
        "# Save the model's weights, configuration, and vocabulary to the specified path\n",
        "model.save_pretrained(model_path)\n",
        "\n",
        "# Save the tokenizer's vocabulary and tokenizer configuration to the specified path\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iGMAzFbOUk-"
      },
      "outputs": [],
      "source": [
        "# # Define the path where the pre-trained model and tokenizer are saved\n",
        "# model_path = '/content/drive/MyDrive/Projects/BERT QA'\n",
        "\n",
        "# # Load the pre-trained BERT model from the specified path\n",
        "# model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "\n",
        "# # Load the tokenizer from the specified path\n",
        "# tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "# # Check the available device and use GPU if available, otherwise use CPU\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# # Move the model to the appropriate device\n",
        "# model = model.to(device)\n",
        "\n",
        "# # Print the device being used\n",
        "# print(f'Working on {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmQSlVmmOUjO"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize a list to store accuracy values\n",
        "acc = []\n",
        "\n",
        "# Iterate over batches in the validation data\n",
        "for batch in tqdm(valid_loader):\n",
        "    with torch.no_grad():\n",
        "        # Move input tensors to the appropriate device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        start_true = batch['start_positions'].to(device)\n",
        "        end_true = batch['end_positions'].to(device)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Get predicted start and end positions\n",
        "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "        # Compute accuracy for start positions and end positions\n",
        "        acc.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
        "        acc.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
        "\n",
        "# Compute the average accuracy\n",
        "acc = sum(acc) / len(acc)\n",
        "\n",
        "# Print the header for true and predicted answer positions\n",
        "print(\"\\n\\nT/P\\tanswer_start\\tanswer_end\\n\")\n",
        "\n",
        "# Print true and predicted start and end positions for each example\n",
        "for i in range(len(start_true)):\n",
        "    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n",
        "          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuCwUQIGOUgG"
      },
      "outputs": [],
      "source": [
        "def get_prediction(context, question):\n",
        "    \"\"\"\n",
        "    Get the predicted answer for a given context and question.\n",
        "\n",
        "    Parameters:\n",
        "    - context: The context in which the question is asked\n",
        "    - question: The question to be answered\n",
        "\n",
        "    Returns:\n",
        "    - answer: The predicted answer to the question\n",
        "    \"\"\"\n",
        "    # Tokenize the question and context\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt').to(device)\n",
        "    # Perform inference using the model\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Get the predicted start and end positions\n",
        "    answer_start = torch.argmax(outputs[0])\n",
        "    answer_end = torch.argmax(outputs[1]) + 1\n",
        "\n",
        "    # Convert the predicted token IDs to string\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    return answer\n",
        "\n",
        "def normalize_text(s):\n",
        "    \"\"\"\n",
        "    Normalize text by removing articles, punctuation, and standardizing whitespace.\n",
        "\n",
        "    Parameters:\n",
        "    - s: Input text to be normalized\n",
        "\n",
        "    Returns:\n",
        "    - Normalized text\n",
        "    \"\"\"\n",
        "    import string, re\n",
        "\n",
        "    # Function to remove articles from text\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    # Function to fix white space in text\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    # Function to remove punctuation from text\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Function to convert text to lowercase\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    # Apply text normalization steps\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def exact_match(prediction, truth):\n",
        "    \"\"\"\n",
        "    Compute exact match between predicted answer and true answer.\n",
        "\n",
        "    Parameters:\n",
        "    - prediction: Predicted answer\n",
        "    - truth: True answer\n",
        "\n",
        "    Returns:\n",
        "    - Boolean indicating whether the prediction exactly matches the truth\n",
        "    \"\"\"\n",
        "    return bool(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    \"\"\"\n",
        "    Compute F1 score between predicted answer and true answer.\n",
        "\n",
        "    Parameters:\n",
        "    - prediction: Predicted answer\n",
        "    - truth: True answer\n",
        "\n",
        "    Returns:\n",
        "    - F1 score\n",
        "    \"\"\"\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "\n",
        "    # If either the prediction or the truth is no-answer then F1 score is 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "\n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "\n",
        "    # If there are no common tokens then F1 score is 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "\n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "\n",
        "    return round(2 * (prec * rec) / (prec + rec), 2)\n",
        "\n",
        "def question_answer(context, question, answer):\n",
        "    \"\"\"\n",
        "    Ask a question given a context and compare the predicted answer to the true answer.\n",
        "\n",
        "    Parameters:\n",
        "    - context: The context in which the question is asked\n",
        "    - question: The question to be answered\n",
        "    - answer: The true answer to the question\n",
        "\n",
        "    Returns:\n",
        "    None (prints the results)\n",
        "    \"\"\"\n",
        "    # Get the predicted answer for the question\n",
        "    prediction = get_prediction(context, question)\n",
        "    # Compute exact match score\n",
        "    em_score = exact_match(prediction, answer)\n",
        "    # Compute F1 score\n",
        "    f1_score = compute_f1(prediction, answer)\n",
        "\n",
        "    # Print the results\n",
        "    print(f'Question: {question}')\n",
        "    print(f'Prediction: {prediction}')\n",
        "    print(f'True Answer: {answer}')\n",
        "    print(f'Exact match: {em_score}')\n",
        "    print(f'F1 score: {f1_score}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUVtk72ELLER",
        "outputId": "63591f0d-afcd-441a-adff-6166aea708bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What did Albert Einstein develop?\n",
            "Prediction: theory of relativity\n",
            "True Answer: theory of relativity\n",
            "Exact match: True\n",
            "F1 score: 1.0\n",
            "\n",
            "Question: Where was Albert Einstein born?\n",
            "Prediction: german\n",
            "True Answer: german\n",
            "Exact match: True\n",
            "F1 score: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\"\"Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics).\"\"\"\n",
        "\n",
        "\n",
        "questions = [\"What did Albert Einstein develop?\",\n",
        "             \"Where was Albert Einstein born?\"]\n",
        "\n",
        "answers = [\"theory of relativity\", \"german\"]\n",
        "\n",
        "for question, answer in zip(questions, answers):\n",
        "  question_answer(context, question, answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7721-gl4iFS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbE5d6JCW105"
      },
      "outputs": [],
      "source": [
        "# https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n",
        "\"\"\"Official evaluation script for SQuAD version 2.0.\n",
        "\n",
        "In addition to basic functionality, we also compute additional statistics and\n",
        "plot precision-recall curves if an additional na_prob.json file is provided.\n",
        "This file is expected to map question ID's to the model's predicted probability\n",
        "that a question is unanswerable.\n",
        "\"\"\"\n",
        "'''\n",
        "import argparse\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "\n",
        "OPTS = None\n",
        "\n",
        "def parse_args():\n",
        "  parser = argparse.ArgumentParser('Official evaluation script for SQuAD version 2.0.')\n",
        "  parser.add_argument('data_file', metavar='data.json', help='Input data JSON file.')\n",
        "  parser.add_argument('pred_file', metavar='pred.json', help='Model predictions.')\n",
        "  parser.add_argument('--out-file', '-o', metavar='eval.json',\n",
        "                      help='Write accuracy metrics to file (default is stdout).')\n",
        "  parser.add_argument('--na-prob-file', '-n', metavar='na_prob.json',\n",
        "                      help='Model estimates of probability of no answer.')\n",
        "  parser.add_argument('--na-prob-thresh', '-t', type=float, default=1.0,\n",
        "                      help='Predict \"\" if no-answer probability exceeds this (default = 1.0).')\n",
        "  parser.add_argument('--out-image-dir', '-p', metavar='out_images', default=None,\n",
        "                      help='Save precision-recall curves to directory.')\n",
        "  parser.add_argument('--verbose', '-v', action='store_true')\n",
        "  if len(sys.argv) == 1:\n",
        "    parser.print_help()\n",
        "    sys.exit(1)\n",
        "  return parser.parse_args()\n",
        "\n",
        "def make_qid_to_has_ans(dataset):\n",
        "  qid_to_has_ans = {}\n",
        "  for article in dataset:\n",
        "    for p in article['paragraphs']:\n",
        "      for qa in p['qas']:\n",
        "        qid_to_has_ans[qa['id']] = bool(qa['answers'])\n",
        "  return qid_to_has_ans\n",
        "\n",
        "def normalize_answer(s):\n",
        "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "    return re.sub(regex, ' ', text)\n",
        "  def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def get_tokens(s):\n",
        "  if not s: return []\n",
        "  return normalize_answer(s).split()\n",
        "\n",
        "def compute_exact(a_gold, a_pred):\n",
        "  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "\n",
        "def compute_f1(a_gold, a_pred):\n",
        "  gold_toks = get_tokens(a_gold)\n",
        "  pred_toks = get_tokens(a_pred)\n",
        "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "  num_same = sum(common.values())\n",
        "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "    return int(gold_toks == pred_toks)\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "  precision = 1.0 * num_same / len(pred_toks)\n",
        "  recall = 1.0 * num_same / len(gold_toks)\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "  return f1\n",
        "\n",
        "def get_raw_scores(dataset, preds):\n",
        "  exact_scores = {}\n",
        "  f1_scores = {}\n",
        "  for article in dataset:\n",
        "    for p in article['paragraphs']:\n",
        "      for qa in p['qas']:\n",
        "        qid = qa['id']\n",
        "        gold_answers = [a['text'] for a in qa['answers']\n",
        "                        if normalize_answer(a['text'])]\n",
        "        if not gold_answers:\n",
        "          # For unanswerable questions, only correct answer is empty string\n",
        "          gold_answers = ['']\n",
        "        if qid not in preds:\n",
        "          print('Missing prediction for %s' % qid)\n",
        "          continue\n",
        "        a_pred = preds[qid]\n",
        "        # Take max over all gold answers\n",
        "        exact_scores[qid] = max(compute_exact(a, a_pred) for a in gold_answers)\n",
        "        f1_scores[qid] = max(compute_f1(a, a_pred) for a in gold_answers)\n",
        "  return exact_scores, f1_scores\n",
        "\n",
        "def apply_no_ans_threshold(scores, na_probs, qid_to_has_ans, na_prob_thresh):\n",
        "  new_scores = {}\n",
        "  for qid, s in scores.items():\n",
        "    pred_na = na_probs[qid] > na_prob_thresh\n",
        "    if pred_na:\n",
        "      new_scores[qid] = float(not qid_to_has_ans[qid])\n",
        "    else:\n",
        "      new_scores[qid] = s\n",
        "  return new_scores\n",
        "\n",
        "def make_eval_dict(exact_scores, f1_scores, qid_list=None):\n",
        "  if not qid_list:\n",
        "    total = len(exact_scores)\n",
        "    return collections.OrderedDict([\n",
        "        ('exact', 100.0 * sum(exact_scores.values()) / total),\n",
        "        ('f1', 100.0 * sum(f1_scores.values()) / total),\n",
        "        ('total', total),\n",
        "    ])\n",
        "  else:\n",
        "    total = len(qid_list)\n",
        "    return collections.OrderedDict([\n",
        "        ('exact', 100.0 * sum(exact_scores[k] for k in qid_list) / total),\n",
        "        ('f1', 100.0 * sum(f1_scores[k] for k in qid_list) / total),\n",
        "        ('total', total),\n",
        "    ])\n",
        "\n",
        "def merge_eval(main_eval, new_eval, prefix):\n",
        "  for k in new_eval:\n",
        "    main_eval['%s_%s' % (prefix, k)] = new_eval[k]\n",
        "\n",
        "def plot_pr_curve(precisions, recalls, out_image, title):\n",
        "  plt.step(recalls, precisions, color='b', alpha=0.2, where='post')\n",
        "  plt.fill_between(recalls, precisions, step='post', alpha=0.2, color='b')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.xlim([0.0, 1.05])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.title(title)\n",
        "  plt.savefig(out_image)\n",
        "  plt.clf()\n",
        "\n",
        "def make_precision_recall_eval(scores, na_probs, num_true_pos, qid_to_has_ans,\n",
        "                               out_image=None, title=None):\n",
        "  qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n",
        "  true_pos = 0.0\n",
        "  cur_p = 1.0\n",
        "  cur_r = 0.0\n",
        "  precisions = [1.0]\n",
        "  recalls = [0.0]\n",
        "  avg_prec = 0.0\n",
        "  for i, qid in enumerate(qid_list):\n",
        "    if qid_to_has_ans[qid]:\n",
        "      true_pos += scores[qid]\n",
        "    cur_p = true_pos / float(i+1)\n",
        "    cur_r = true_pos / float(num_true_pos)\n",
        "    if i == len(qid_list) - 1 or na_probs[qid] != na_probs[qid_list[i+1]]:\n",
        "      # i.e., if we can put a threshold after this point\n",
        "      avg_prec += cur_p * (cur_r - recalls[-1])\n",
        "      precisions.append(cur_p)\n",
        "      recalls.append(cur_r)\n",
        "  if out_image:\n",
        "    plot_pr_curve(precisions, recalls, out_image, title)\n",
        "  return {'ap': 100.0 * avg_prec}\n",
        "\n",
        "def run_precision_recall_analysis(main_eval, exact_raw, f1_raw, na_probs,\n",
        "                                  qid_to_has_ans, out_image_dir):\n",
        "  if out_image_dir and not os.path.exists(out_image_dir):\n",
        "    os.makedirs(out_image_dir)\n",
        "  num_true_pos = sum(1 for v in qid_to_has_ans.values() if v)\n",
        "  if num_true_pos == 0:\n",
        "    return\n",
        "  pr_exact = make_precision_recall_eval(\n",
        "      exact_raw, na_probs, num_true_pos, qid_to_has_ans,\n",
        "      out_image=os.path.join(out_image_dir, 'pr_exact.png'),\n",
        "      title='Precision-Recall curve for Exact Match score')\n",
        "  pr_f1 = make_precision_recall_eval(\n",
        "      f1_raw, na_probs, num_true_pos, qid_to_has_ans,\n",
        "      out_image=os.path.join(out_image_dir, 'pr_f1.png'),\n",
        "      title='Precision-Recall curve for F1 score')\n",
        "  oracle_scores = {k: float(v) for k, v in qid_to_has_ans.items()}\n",
        "  pr_oracle = make_precision_recall_eval(\n",
        "      oracle_scores, na_probs, num_true_pos, qid_to_has_ans,\n",
        "      out_image=os.path.join(out_image_dir, 'pr_oracle.png'),\n",
        "      title='Oracle Precision-Recall curve (binary task of HasAns vs. NoAns)')\n",
        "  merge_eval(main_eval, pr_exact, 'pr_exact')\n",
        "  merge_eval(main_eval, pr_f1, 'pr_f1')\n",
        "  merge_eval(main_eval, pr_oracle, 'pr_oracle')\n",
        "\n",
        "def histogram_na_prob(na_probs, qid_list, image_dir, name):\n",
        "  if not qid_list:\n",
        "    return\n",
        "  x = [na_probs[k] for k in qid_list]\n",
        "  weights = np.ones_like(x) / float(len(x))\n",
        "  plt.hist(x, weights=weights, bins=20, range=(0.0, 1.0))\n",
        "  plt.xlabel('Model probability of no-answer')\n",
        "  plt.ylabel('Proportion of dataset')\n",
        "  plt.title('Histogram of no-answer probability: %s' % name)\n",
        "  plt.savefig(os.path.join(image_dir, 'na_prob_hist_%s.png' % name))\n",
        "  plt.clf()\n",
        "\n",
        "def find_best_thresh(preds, scores, na_probs, qid_to_has_ans):\n",
        "  num_no_ans = sum(1 for k in qid_to_has_ans if not qid_to_has_ans[k])\n",
        "  cur_score = num_no_ans\n",
        "  best_score = cur_score\n",
        "  best_thresh = 0.0\n",
        "  qid_list = sorted(na_probs, key=lambda k: na_probs[k])\n",
        "  for i, qid in enumerate(qid_list):\n",
        "    if qid not in scores: continue\n",
        "    if qid_to_has_ans[qid]:\n",
        "      diff = scores[qid]\n",
        "    else:\n",
        "      if preds[qid]:\n",
        "        diff = -1\n",
        "      else:\n",
        "        diff = 0\n",
        "    cur_score += diff\n",
        "    if cur_score > best_score:\n",
        "      best_score = cur_score\n",
        "      best_thresh = na_probs[qid]\n",
        "  return 100.0 * best_score / len(scores), best_thresh\n",
        "\n",
        "def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans):\n",
        "  best_exact, exact_thresh = find_best_thresh(preds, exact_raw, na_probs, qid_to_has_ans)\n",
        "  best_f1, f1_thresh = find_best_thresh(preds, f1_raw, na_probs, qid_to_has_ans)\n",
        "  main_eval['best_exact'] = best_exact\n",
        "  main_eval['best_exact_thresh'] = exact_thresh\n",
        "  main_eval['best_f1'] = best_f1\n",
        "  main_eval['best_f1_thresh'] = f1_thresh\n",
        "\n",
        "def main():\n",
        "  with open(OPTS.data_file) as f:\n",
        "    dataset_json = json.load(f)\n",
        "    dataset = dataset_json['data']\n",
        "  with open(OPTS.pred_file) as f:\n",
        "    preds = json.load(f)\n",
        "  if OPTS.na_prob_file:\n",
        "    with open(OPTS.na_prob_file) as f:\n",
        "      na_probs = json.load(f)\n",
        "  else:\n",
        "    na_probs = {k: 0.0 for k in preds}\n",
        "  qid_to_has_ans = make_qid_to_has_ans(dataset)  # maps qid to True/False\n",
        "  has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
        "  no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n",
        "  exact_raw, f1_raw = get_raw_scores(dataset, preds)\n",
        "  exact_thresh = apply_no_ans_threshold(exact_raw, na_probs, qid_to_has_ans,\n",
        "                                        OPTS.na_prob_thresh)\n",
        "  f1_thresh = apply_no_ans_threshold(f1_raw, na_probs, qid_to_has_ans,\n",
        "                                     OPTS.na_prob_thresh)\n",
        "  out_eval = make_eval_dict(exact_thresh, f1_thresh)\n",
        "  if has_ans_qids:\n",
        "    has_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=has_ans_qids)\n",
        "    merge_eval(out_eval, has_ans_eval, 'HasAns')\n",
        "  if no_ans_qids:\n",
        "    no_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=no_ans_qids)\n",
        "    merge_eval(out_eval, no_ans_eval, 'NoAns')\n",
        "  if OPTS.na_prob_file:\n",
        "    find_all_best_thresh(out_eval, preds, exact_raw, f1_raw, na_probs, qid_to_has_ans)\n",
        "  if OPTS.na_prob_file and OPTS.out_image_dir:\n",
        "    run_precision_recall_analysis(out_eval, exact_raw, f1_raw, na_probs,\n",
        "                                  qid_to_has_ans, OPTS.out_image_dir)\n",
        "    histogram_na_prob(na_probs, has_ans_qids, OPTS.out_image_dir, 'hasAns')\n",
        "    histogram_na_prob(na_probs, no_ans_qids, OPTS.out_image_dir, 'noAns')\n",
        "  if OPTS.out_file:\n",
        "    with open(OPTS.out_file, 'w') as f:\n",
        "      json.dump(out_eval, f)\n",
        "  else:\n",
        "    print(json.dumps(out_eval, indent=2))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  OPTS = parse_args()\n",
        "  if OPTS.out_image_dir:\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "  main()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ZKVnusu7V3"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets -q\n",
        "#! pip install -U accelerate\n",
        "#! pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAj2ZYDyFQES"
      },
      "outputs": [],
      "source": [
        "# # Print the structure of the loaded dataset\n",
        "# print(squad[\"train\"].features)\n",
        "'''\n",
        "{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UwHE4CqKy-Tt"
      },
      "outputs": [],
      "source": [
        "'''# code version 1\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
        "\n",
        "# Check if GPU is available, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load SQuAD dataset\n",
        "squad = load_dataset(\"squad\", split=\"train[:5000]\") #change\n",
        "squad = squad.train_test_split(test_size=0.2)\n",
        "\n",
        "# Convert dataset to DataFrames\n",
        "df_train = pd.DataFrame.from_dict(squad[\"train\"].to_dict())\n",
        "df_test = pd.DataFrame.from_dict(squad[\"test\"].to_dict())\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def preprocess_data(data_frame):\n",
        "    \"\"\"\n",
        "    Preprocesses data for question answering model.\n",
        "\n",
        "    Args:\n",
        "        data_frame (pandas.DataFrame): DataFrame containing columns 'question', 'context', and 'answers'.\n",
        "\n",
        "    Returns:\n",
        "        datasets.Dataset: Preprocessed dataset containing input_ids, attention_mask,\n",
        "                          start_positions, and end_positions.\n",
        "    \"\"\"\n",
        "    questions = [q.strip() for q in data_frame[\"question\"]]\n",
        "    contexts = [c.strip() for c in data_frame[\"context\"]]\n",
        "    answers = data_frame['answers']\n",
        "\n",
        "    # Tokenize inputs\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        max_length=512,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mappings = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Determine start and end positions for answers\n",
        "    for i, offset_mapping in enumerate(offset_mappings):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        context_start = next(idx for idx, seq_id in enumerate(sequence_ids) if seq_id == 1)\n",
        "        context_end = next(idx for idx, seq_id in enumerate(sequence_ids[context_start:], start=context_start) if seq_id != 1) - 1\n",
        "\n",
        "        if offset_mapping[context_start][0] > end_char or offset_mapping[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            start_positions.append(next(idx for idx, offset in enumerate(offset_mapping[context_start:], start=context_start) if offset[0] <= start_char) - 1)\n",
        "            end_positions.append(next(idx for idx, offset in enumerate(offset_mapping[context_end:], start=context_end) if offset[1] >= end_char) + 1)\n",
        "\n",
        "    data_frame[\"start_positions\"] = start_positions\n",
        "    data_frame[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Create dataset\n",
        "    data = {\n",
        "        'input_ids': inputs['input_ids'],\n",
        "        'attention_mask': inputs['attention_mask'],\n",
        "        'start_positions': start_positions,\n",
        "        'end_positions': end_positions,\n",
        "    }\n",
        "    data_frame = pd.DataFrame(data)\n",
        "    dataset = Dataset.from_pandas(data_frame)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Preprocess train and test datasets\n",
        "train_dataset = preprocess_data(df_train)\n",
        "eval_dataset = preprocess_data(df_test)\n",
        "\n",
        "# Initialize model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "# Initialize data collator\n",
        "data_collator = default_data_collator\n",
        "\n",
        "# Training arguments\n",
        "output_dir = \"./fine-tuned-model\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",  # Disable logging\n",
        "    save_strategy=\"epoch\",  # Save checkpoint after each epoch\n",
        "    save_total_limit=3,  # Save only the last 3 checkpoints\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Evaluation function\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    start_logits, end_logits = predictions\n",
        "    start_positions, end_positions = labels\n",
        "\n",
        "    # Decode the predictions\n",
        "    start_logits = torch.from_numpy(start_logits)\n",
        "    end_logits = torch.from_numpy(end_logits)\n",
        "\n",
        "    predictions_start = torch.argmax(start_logits).item()\n",
        "    predictions_end = torch.argmax(end_logits).item()\n",
        "\n",
        "    exact_match = ((predictions_start == start_positions) & (predictions_end == end_positions)).sum().item()\n",
        "\n",
        "    return {\"exact_match\": exact_match}\n",
        "\n",
        "trainer.compute_metrics = compute_metrics\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model after training\n",
        "model.save_pretrained(output_dir)\n",
        "\n",
        "# Test user input\n",
        "# Load the fine-tuned model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(output_dir)\n",
        "\n",
        "# Function to get answer from the model\n",
        "def get_answer(question, context):\n",
        "    inputs = tokenizer(\n",
        "        question,\n",
        "        context,\n",
        "        max_length=512,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "    return answer\n",
        "\n",
        "# Test the model interactively\n",
        "while True:\n",
        "    # Get user input\n",
        "    question = input(\"Enter a question (type 'quit' to exit): \")\n",
        "    if question.lower() == 'quit':\n",
        "        break\n",
        "    context = input(\"Enter the context: \")\n",
        "\n",
        "    # Get and print the answer\n",
        "    answer = get_answer(question, context)\n",
        "    print(\"Answer:\", answer)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggy9ydYybmD3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00f84bf7038e481d9c0984501690fd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06aafb298e06406ead8ce2d412694b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3e0ef67aa64e6ebab541017a28f273",
            "placeholder": "​",
            "style": "IPY_MODEL_00f84bf7038e481d9c0984501690fd75",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0c1475e26d954587a96e3de6ce7fba09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ca3c72439604224bacbcd32941cf347": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b09def97ea430f94f515a033bade19",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5338ea914b04a1185a983fec9642b11",
            "value": 231508
          }
        },
        "185eb78f7f2344fb8bb2d22f4dee993e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acce1d7dea14d09b57039baa9c4d524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d25e31523631405aaa5aee90340cbd74",
              "IPY_MODEL_0ca3c72439604224bacbcd32941cf347",
              "IPY_MODEL_d1e5720c1d1341b1a2eea3dd6a2e6f79"
            ],
            "layout": "IPY_MODEL_3c7f2cfe590449e597ddea87ec27c566"
          }
        },
        "1de52722f83f44f2a2d62b6a75d45436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207e083105734c929fe093b128542fe4",
            "placeholder": "​",
            "style": "IPY_MODEL_6c3abc9b81614cd39b0ae11f28edb020",
            "value": "tokenizer.json: 100%"
          }
        },
        "207e083105734c929fe093b128542fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dada988d597404bb88b06fa28f9be54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8d2f8be0d9480ebe9a69b7ed19fcac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f0c693adc44c2a939c5939f28c6864": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3332d175b519437e99cc2f57c754ed5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "363b2a9771e14a53ac146091fd7ce06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1de52722f83f44f2a2d62b6a75d45436",
              "IPY_MODEL_965414e9b4c34e639a4f9f423852a100",
              "IPY_MODEL_6beeb986f16a491f85bef981ef21eeac"
            ],
            "layout": "IPY_MODEL_e92cb97cf67f49d9af2038bd957a9537"
          }
        },
        "3c7f2cfe590449e597ddea87ec27c566": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447b3fc6e01b49429b0e4120bb39c239": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47a16d74ae984ef494be0fa1c948c184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497b79d732b6445e947cb7ee15861953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dada988d597404bb88b06fa28f9be54",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a02609f0aa54aa9967710cd137bd0d6",
            "value": 28
          }
        },
        "4b28d8cf21f44e38a2123331cf99eaa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c542912183743feb9d966633eead8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dfdaf644e92499d9567fb318c228ead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e33f3851dc340ea8055735a0d180d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfdaf644e92499d9567fb318c228ead",
            "placeholder": "​",
            "style": "IPY_MODEL_0c1475e26d954587a96e3de6ce7fba09",
            "value": " 440M/440M [00:10&lt;00:00, 24.1MB/s]"
          }
        },
        "57c8e744b1ff46498d11c89753073e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f709dda46a74ae199ba2aa9be4e5df3",
            "placeholder": "​",
            "style": "IPY_MODEL_7bc2500103ae447a9ce0c2a7c44e9f72",
            "value": "config.json: 100%"
          }
        },
        "5f709dda46a74ae199ba2aa9be4e5df3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fb66562363416fbb543f8553a203ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a1e5d12390a4c50b16a1080ecbd116e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06aafb298e06406ead8ce2d412694b4a",
              "IPY_MODEL_497b79d732b6445e947cb7ee15861953",
              "IPY_MODEL_fc3056d68ce74432ba503305e4dafc46"
            ],
            "layout": "IPY_MODEL_db8e2eb968724e76a0dde7f8e69c825a"
          }
        },
        "6beeb986f16a491f85bef981ef21eeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8d2f8be0d9480ebe9a69b7ed19fcac",
            "placeholder": "​",
            "style": "IPY_MODEL_30f0c693adc44c2a939c5939f28c6864",
            "value": " 466k/466k [00:00&lt;00:00, 1.86MB/s]"
          }
        },
        "6c3abc9b81614cd39b0ae11f28edb020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3e0ef67aa64e6ebab541017a28f273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc2500103ae447a9ce0c2a7c44e9f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a02609f0aa54aa9967710cd137bd0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a1a906308814fe0a89da55b134649c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910f299530a7405bb3da2a311d3d6fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941f7b33b5134e759ad44b26feaf2c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57c8e744b1ff46498d11c89753073e7b",
              "IPY_MODEL_dab4d8388b37478eab5c81e2ad5493b2",
              "IPY_MODEL_dad87cf60ec344ada7caa8d8634c14c6"
            ],
            "layout": "IPY_MODEL_8a1a906308814fe0a89da55b134649c0"
          }
        },
        "965414e9b4c34e639a4f9f423852a100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e6794ab95747da956c28b802995a9c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c542912183743feb9d966633eead8a2",
            "value": 466062
          }
        },
        "a4f83b6692a54ba69222a8e969e38f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b28d8cf21f44e38a2123331cf99eaa4",
            "placeholder": "​",
            "style": "IPY_MODEL_447b3fc6e01b49429b0e4120bb39c239",
            "value": "model.safetensors: 100%"
          }
        },
        "a71adba54b84439cb03c19a5706d806d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a825de9638f7428193afeebd6c262301": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b5b6a5098642f9879a04f2d112c319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4f83b6692a54ba69222a8e969e38f62",
              "IPY_MODEL_deb34ba70a58401390a5785f7ea9c902",
              "IPY_MODEL_4e33f3851dc340ea8055735a0d180d7d"
            ],
            "layout": "IPY_MODEL_d4590c782677412fb6cd7563c413d45a"
          }
        },
        "b9e6794ab95747da956c28b802995a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1382ede91cd48aaa6d20c534f82878b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c639665ad225412f91d313a0cf5b4bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8b09def97ea430f94f515a033bade19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd62b340578a4615975fe06c17dfce2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1e5720c1d1341b1a2eea3dd6a2e6f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a825de9638f7428193afeebd6c262301",
            "placeholder": "​",
            "style": "IPY_MODEL_3332d175b519437e99cc2f57c754ed5b",
            "value": " 232k/232k [00:00&lt;00:00, 3.76MB/s]"
          }
        },
        "d25e31523631405aaa5aee90340cbd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71adba54b84439cb03c19a5706d806d",
            "placeholder": "​",
            "style": "IPY_MODEL_cd62b340578a4615975fe06c17dfce2f",
            "value": "vocab.txt: 100%"
          }
        },
        "d4590c782677412fb6cd7563c413d45a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5338ea914b04a1185a983fec9642b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dab4d8388b37478eab5c81e2ad5493b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910f299530a7405bb3da2a311d3d6fa0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd4940d554d649c9b364c8d88b4a09f0",
            "value": 570
          }
        },
        "dad87cf60ec344ada7caa8d8634c14c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62fb66562363416fbb543f8553a203ac",
            "placeholder": "​",
            "style": "IPY_MODEL_e3a8d1cfec4c44e38b5f1dbe0c88fa77",
            "value": " 570/570 [00:00&lt;00:00, 41.6kB/s]"
          }
        },
        "db8e2eb968724e76a0dde7f8e69c825a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4940d554d649c9b364c8d88b4a09f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "deb34ba70a58401390a5785f7ea9c902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_185eb78f7f2344fb8bb2d22f4dee993e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c639665ad225412f91d313a0cf5b4bd9",
            "value": 440449768
          }
        },
        "e3a8d1cfec4c44e38b5f1dbe0c88fa77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92cb97cf67f49d9af2038bd957a9537": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3056d68ce74432ba503305e4dafc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1382ede91cd48aaa6d20c534f82878b",
            "placeholder": "​",
            "style": "IPY_MODEL_47a16d74ae984ef494be0fa1c948c184",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.07kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
